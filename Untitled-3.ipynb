{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Obtaining dependency information for torchtext from https://files.pythonhosted.org/packages/ce/e1/b1d577578800a603cbeead5f52d46649a413a8132414131a944284fdaeb5/torchtext-0.17.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchtext-0.17.2-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\colin\\appdata\\roaming\\python\\python311\\site-packages (from torchtext) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (2.28.1)\n",
      "Requirement already satisfied: torch==2.2.2 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (1.23.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2->torchtext) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2->torchtext) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2->torchtext) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2->torchtext) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2->torchtext) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2->torchtext) (2023.9.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (2022.9.24)\n",
      "Requirement already satisfied: colorama in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch==2.2.2->torchtext) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch==2.2.2->torchtext) (1.3.0)\n",
      "Downloading torchtext-0.17.2-cp311-cp311-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 1.9/1.9 MB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.6.0\n",
      "  Obtaining dependency information for torchtext==0.6.0 from https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\colin\\appdata\\roaming\\python\\python311\\site-packages (from torchtext==0.6.0) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext==0.6.0) (2.28.1)\n",
      "Requirement already satisfied: torch in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext==0.6.0) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext==0.6.0) (1.23.5)\n",
      "Requirement already satisfied: six in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext==0.6.0) (1.16.0)\n",
      "Collecting sentencepiece (from torchtext==0.6.0)\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/a2/f6/587c62fd21fc988555b85351f50bbde43a51524caafd63bc69240ded14fd/sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext==0.6.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext==0.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext==0.6.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext==0.6.0) (2022.9.24)\n",
      "Requirement already satisfied: filelock in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->torchtext==0.6.0) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->torchtext==0.6.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->torchtext==0.6.0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->torchtext==0.6.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->torchtext==0.6.0) (2023.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->torchtext==0.6.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch->torchtext==0.6.0) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
      "Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 64.2/64.2 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   --------------------------------------- 991.5/991.5 kB 20.9 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.17.2\n",
      "    Uninstalling torchtext-0.17.2:\n",
      "      Successfully uninstalled torchtext-0.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\colin\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\~orchtext\\\\lib\\\\libtorchtext.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torchtext import data as d, datasets\n",
    "# from data import Field, TabularDataset, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "from spacy.cli.download import download\n",
    "\n",
    "download(model=\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define TorchText fields for text processing\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m TEXT \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspacy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m LABEL \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mField(sequential\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load your dataset\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\colin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchtext\\data\\field.py:163\u001b[0m, in \u001b[0;36mField.__init__\u001b[1;34m(self, sequential, use_vocab, init_token, eos_token, fix_length, dtype, preprocessing, postprocessing, lower, tokenize, tokenizer_language, include_lengths, batch_first, pad_token, unk_token, pad_first, truncate_first, stop_words, is_target)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# store params to construct tokenizer for serialization\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# in case the tokenizer isn't picklable (e.g. spacy)\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer_args \u001b[38;5;241m=\u001b[39m (tokenize, tokenizer_language)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_language\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_lengths \u001b[38;5;241m=\u001b[39m include_lengths\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;241m=\u001b[39m batch_first\n",
      "File \u001b[1;32mc:\\Users\\colin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchtext\\data\\utils.py:114\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[1;34m(tokenizer, language)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     spacy \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m partial(_spacy_tokenize, spacy\u001b[38;5;241m=\u001b[39mspacy)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\colin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\colin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:438\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
     ]
    }
   ],
   "source": [
    "# Define TorchText fields for text processing\n",
    "TEXT = d.Field(tokenize='spacy', include_lengths=True)\n",
    "LABEL = d.Field(sequential=False, use_vocab=False, dtype=torch.float)\n",
    "\n",
    "# Load your dataset\n",
    "train_data, valid_data, test_data = d.TabularDataset.splits(\n",
    "    path='', train='Resume.csv',\n",
    "    validation='valid.csv', test='test.csv', format='csv',\n",
    "    fields=[('text', TEXT), ('label', LABEL)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build vocabulary\n",
    "TEXT.build_vocab(train_data, max_size=10000)\n",
    "\n",
    "# Define iterators\n",
    "train_iterator, valid_iterator, test_iterator = d.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=64,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "\n",
    "class NLPMatcher(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        return self.fc(hidden)\n",
    "\n",
    "\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = NLPMatcher(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "N_EPOCHS = 20\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Valid Loss: {valid_loss:.3f}')\n",
    "\n",
    "# test_loss = evaluate(model, test_iterator, criterion)\n",
    "# print(f'Test Loss: {test_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Obtaining dependency information for sentence_transformers from https://files.pythonhosted.org/packages/76/2c/bd95032aeb087b0706596af0a4518c4bfe0439a1bb149048ece18b617766/sentence_transformers-2.7.0-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.34.0 from https://files.pythonhosted.org/packages/cf/90/2596ac2ab49c4df6ff1fceaf7f5afb18401ba2f326348ce1a6261a65e7ed/transformers-4.40.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "     -------------------------------------- 138.0/138.0 kB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\colin\\appdata\\roaming\\python\\python311\\site-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence_transformers) (1.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence_transformers) (1.9.3)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence_transformers)\n",
      "  Obtaining dependency information for huggingface-hub>=0.15.1 from https://files.pythonhosted.org/packages/05/c0/779afbad8e75565c09ffa24a88b5dd7e293c92b74eb09df6435fc58ac986/huggingface_hub-0.22.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.12.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\colin\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2022.10.31)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/65/8e/6d7d72b28f22c422cff8beae10ac3c2e4376b9be721ef8167b7eecd1da62/tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/cb/f6/19f268662be898ff2a23ac06f8dd0d2956b2ecd204c96e1ee07ba292c119/safetensors-0.4.3-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence_transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2022.9.24)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\colin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "   --------------------------------------- 171.5/171.5 kB 10.7 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "   --------------------------------------- 388.9/388.9 kB 23.7 MB/s eta 0:00:00\n",
      "Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "   ---------------------------------------- 9.0/9.0 MB 63.7 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "   --------------------------------------- 287.3/287.3 kB 17.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 2.2/2.2 MB 69.1 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
      "Successfully installed huggingface-hub-0.22.2 safetensors-0.4.3 sentence_transformers-2.7.0 tokenizers-0.19.1 transformers-4.40.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install wordcloud\n",
    "# pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colin\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/resume-dataset/Resume/Resume.csv')\n",
    "df.drop(['ID', 'Resume_html'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
